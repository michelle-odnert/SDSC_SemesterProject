---
title: "Correlations"
output: html_document
---

```{r}
library(arrow)
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)
library(patchwork)
library(corrplot)
library(sp)
library(spacetime)
library(gstat)
library(sf)
library(terra)
library(ggrepel)
library(tibble)
library(zoo)      # For rolling windows
```
```{r}
df_psd <- read_parquet("df_illgraben_may_to_sept.parquet")
df_anom <- read_parquet("df_illgraben_anomaly_scores.parquet")
coords <- read.delim("coords.txt", sep = "|", comment.char = "#", 
                     header = FALSE, stringsAsFactors = FALSE)

```

Clean Coords
```{r}
col_names <- c("Network", "Station", "Location", "Channel", "Latitude", "Longitude", 
               "Elevation", "Depth", "Azimuth", "Dip", "SensorDescription", "Scale", 
               "ScaleFreq", "ScaleUnits", "SampleRate", "StartTime", "EndTime")
coords <- coords[-1, ]
names(coords) <- col_names

coords <- coords %>%
  mutate(across(c(Latitude, Longitude, Elevation), as.numeric))

station_coords <- coords %>%
  arrange(Station, desc(StartTime)) %>%
  group_by(Station) %>%
  slice(1) %>%
  ungroup() %>%
  select(Station, Latitude, Longitude, Elevation)
```

Swiss Grid
```{r}
stations_wgs84 <- st_as_sf(station_coords, coords = c("Longitude", "Latitude"), crs = 4326)
stations_mn95 <- st_transform(stations_wgs84, crs = 2056)
stations_mn95_coords <- stations_mn95 %>%
  mutate(X_mn95 = st_coordinates(.)[,1],
         Y_mn95 = st_coordinates(.)[,2],
         Z = Elevation) %>%
  st_drop_geometry() %>%
  select(Station, X_mn95, Y_mn95, Z)

```

Merge Coords
```{r}
df_anom_coords <- df_anom %>%
  left_join(stations_mn95_coords, by = c("station" = "Station")) %>%
  rename(debris_flow = `debris flow`)

cat("Missing coords:", sum(is.na(df_anom_coords$X_mn95)), "\n")
```

Downsample
```{r}
# Define 15-minute window in seconds
window_seconds <- 15 * 60

# Initialize in_event_window column
df_anom_coords$in_event_window <- FALSE

# Loop over each station with debris flow events
stations_with_events <- unique(df_anom_coords$station[df_anom_coords$debris_flow == TRUE])

for (st in stations_with_events) {
  event_times_st <- df_anom_coords$time[df_anom_coords$station == st & df_anom_coords$debris_flow == TRUE]
  
  # Mark rows within ±15 minutes of any event
  idx <- which(df_anom_coords$station == st & sapply(df_anom_coords$time[df_anom_coords$station == st],
                                                     function(t) any(abs(as.numeric(difftime(t, event_times_st, units="secs"))) <= window_seconds)))
  df_anom_coords$in_event_window[idx] <- TRUE
}

cat("Rows in event windows:", sum(df_anom_coords$in_event_window), "\n")

```
```{r}
# Keep all event and event-window rows
df_keep <- df_anom_coords %>%
  filter(debris_flow == TRUE | in_event_window == TRUE)

# Downsample non-event data to 25% per station
set.seed(123)
df_non_event <- df_anom_coords %>%
  filter(debris_flow == FALSE & in_event_window == FALSE) %>%
  group_by(station) %>%
  sample_frac(0.3) %>%
  ungroup()

# Combine both sets
df_sample <- bind_rows(df_keep, df_non_event)

cat("Final sampled data dimensions:", dim(df_sample), "\n")
cat("Total debris flow events:", sum(df_sample$debris_flow), "\n")
cat("Total non-events:", sum(!df_sample$debris_flow), "\n")

```

Temporal Aggregations 15min windows
```{r}
df_clean <- df_sample %>%
  mutate(time_floor = floor_date(time, "15 minutes")) %>%
  group_by(station, time_floor, X_mn95, Y_mn95, Z) %>%
  summarize(anomaly_score = mean(anomaly_score, na.rm = TRUE),
            debris_flow = max(debris_flow, na.rm = TRUE),
            .groups = 'drop')

cat("Aggregated data:", dim(df_clean), "\n")


```
Windows around events
```{r}
# Identify debris flow event times
event_times <- df_clean %>%
  filter(debris_flow == 1) %>%
  distinct(time_floor) %>%
  arrange(time_floor)

# Create event ±15min windows
event_windows <- event_times %>%
  mutate(window_start = time_floor - minutes(15),
         window_end = time_floor + minutes(15))

# Tag rows as 'event window' or 'non-event'
df_clean <- df_clean %>%
  rowwise() %>%
  mutate(event_window = any(time_floor >= event_windows$window_start &
                            time_floor <= event_windows$window_end)) %>%
  ungroup()

table(df_clean$event_window)

```

Missing Station fill
```{r}
all_times <- df_clean %>% distinct(time_floor)
all_stations <- df_clean %>% distinct(station)
full_grid <- expand_grid(station = all_stations$station, time_floor = all_times$time_floor)

df_filled <- full_grid %>%
  left_join(df_clean, by = c("station", "time_floor")) %>%
  arrange(time_floor, station)

cat("After filling:", dim(df_filled), "\n")

```



Correlation Matrices
```{r}
# 1) Create a global flag for event times (time-floor level)
#    event_windows should already exist (from earlier chunk)
if (!exists("event_windows") || nrow(event_windows) == 0) {
  stop("event_windows not found or empty. Make sure you created event_windows earlier.")
}
event_time_floors <- event_windows$time_floor

df_filled <- df_filled %>%
  mutate(time_is_event = time_floor %in% event_time_floors)

# 2) Build event / normal filled tables (keep all station rows for those times)
df_event_filled  <- df_filled %>% filter(time_is_event)
df_normal_filled <- df_filled %>% filter(!time_is_event)

cat("Unique time bins (event):", n_distinct(df_event_filled$time_floor), "\n")
cat("Unique time bins (normal):", n_distinct(df_normal_filled$time_floor), "\n")
cat("Rows (event):", nrow(df_event_filled), " Rows (normal):", nrow(df_normal_filled), "\n\n")

# 3) Per-station non-NA counts in each mode
station_event_counts <- df_event_filled  %>%
  group_by(station) %>%
  summarise(non_na_event = sum(!is.na(anomaly_score)), .groups = "drop") %>%
  arrange(desc(non_na_event))

station_normal_counts <- df_normal_filled %>%
  group_by(station) %>%
  summarise(non_na_normal = sum(!is.na(anomaly_score)), .groups = "drop") %>%
  arrange(desc(non_na_normal))

cat("Per-station non-NA counts (event):\n"); print(station_event_counts)
cat("\nPer-station non-NA counts (normal):\n"); print(station_normal_counts)
cat("\n")

# 4) Make wide matrices (time x station) for event and normal
make_wide <- function(df) {
  df %>%
    select(time_floor, station, anomaly_score) %>%
    pivot_wider(names_from = station, values_from = anomaly_score) %>%
    arrange(time_floor)
}

wide_event  <- make_wide(df_event_filled)
wide_normal <- make_wide(df_normal_filled)

cat("Dimensions wide_event:", dim(wide_event), "\n")
cat("Dimensions wide_normal:", dim(wide_normal), "\n")

# 5) Compute pairwise overlap counts (number of time rows where both stations have non-NA)
compute_pair_overlap <- function(wide_df) {
  if (ncol(wide_df) <= 1) return(NULL) # only time column
  # logical matrix of non-NA per (time x station)
  mat <- !is.na(as.matrix(wide_df[,-1]))  # drop time column
  # matrix multiplication gives counts
  counts <- t(mat) %*% mat
  station_names <- colnames(wide_df)[-1]
  counts <- matrix(as.integer(counts), nrow = ncol(mat), ncol = ncol(mat),
                   dimnames = list(station_names, station_names))
  counts
}

pair_counts_event  <- compute_pair_overlap(wide_event)
pair_counts_normal <- compute_pair_overlap(wide_normal)

cat("Pairwise overlap (event) - summary:\n")
if (!is.null(pair_counts_event)) {
  print(summary(as.vector(pair_counts_event[upper.tri(pair_counts_event)])))
} else cat("No pairwise counts (not enough columns)\n")

cat("\nPairwise overlap (normal) - summary:\n")
if (!is.null(pair_counts_normal)) {
  print(summary(as.vector(pair_counts_normal[upper.tri(pair_counts_normal)])))
} else cat("No pairwise counts (not enough columns)\n")

# 6) Quick plot of overlap counts (heatmap) so you can see which station pairs have data
plot_pair_counts <- function(counts, title = "Pairwise overlap counts") {
  if (is.null(counts)) {
    cat("No counts to plot for", title, "\n"); return(invisible(NULL))
  }
  
  # Convert to numeric (avoid integer overflow)
  counts <- apply(counts, 2, as.numeric)
  counts <- matrix(as.numeric(counts),
                   nrow = nrow(counts),
                   ncol = ncol(counts),
                   dimnames = dimnames(counts))
  
  # Cap values to reasonable range for visibility
  counts[is.infinite(counts) | counts > 1e6] <- NA
  
  # Determine finite range safely
  finite_vals <- counts[is.finite(counts)]
  col_min <- ifelse(length(finite_vals) > 0, min(finite_vals), 0)
  col_max <- ifelse(length(finite_vals) > 0, max(finite_vals), 1)
  
  corrplot(counts,
           method = "color",
           is.corr = FALSE,
           tl.col = "black",
           tl.srt = 45,
           col.lim = c(col_min, col_max),
           main = title)
}

# --- Rerun these two lines ---
plot_pair_counts(pair_counts_event,  "Overlap counts (event windows)")
plot_pair_counts(pair_counts_normal, "Overlap counts (normal windows)")

# 7) Check whether there are any pairs with >= 2 overlapping rows (required for correlation)
min_overlap_event  <- if (!is.null(pair_counts_event))  min(pair_counts_event[upper.tri(pair_counts_event)], na.rm = TRUE) else NA
min_overlap_normal <- if (!is.null(pair_counts_normal)) min(pair_counts_normal[upper.tri(pair_counts_normal)], na.rm = TRUE) else NA
cat("\nMinimum pairwise overlap (event):", min_overlap_event, "\n")
cat("Minimum pairwise overlap (normal):", min_overlap_normal, "\n")

sufficient_pairs_event  <- if (!is.null(pair_counts_event)) sum(pair_counts_event[upper.tri(pair_counts_event)] >= 2, na.rm = TRUE) else 0
sufficient_pairs_normal <- if (!is.null(pair_counts_normal)) sum(pair_counts_normal[upper.tri(pair_counts_normal)] >= 2, na.rm = TRUE) else 0
cat("Pairs with >=2 overlapping rows (event):", sufficient_pairs_event, "\n")
cat("Pairs with >=2 overlapping rows (normal):", sufficient_pairs_normal, "\n\n")

# 8) Compute correlations ONLY if there are sufficient overlaps
safe_cor <- function(wide_df) {
  if (ncol(wide_df) <= 1) return(NULL)
  mat <- as.matrix(wide_df[,-1])
  # require at least 2 pairwise non-NA points for each pair to yield non-NA correlation
  cormat <- cor(mat, use = "pairwise.complete.obs")
  return(cormat)
}

corr_event  <- if (sufficient_pairs_event > 0)  safe_cor(wide_event)  else NULL
corr_normal <- if (sufficient_pairs_normal > 0) safe_cor(wide_normal) else NULL

# 9) Diagnostics for correlation matrices
if (!is.null(corr_event)) {
  offdiag_event_mean <- mean(corr_event[upper.tri(corr_event)], na.rm = TRUE)
  cat("Event corr mean (off-diagonal):", offdiag_event_mean, "\n")
} else cat("Event correlation matrix could not be computed (insufficient overlap)\n")

if (!is.null(corr_normal)) {
  offdiag_normal_mean <- mean(corr_normal[upper.tri(corr_normal)], na.rm = TRUE)
  cat("Normal corr mean (off-diagonal):", offdiag_normal_mean, "\n")
} else cat("Normal correlation matrix could not be computed (insufficient overlap)\n")

# 10) Plot correlation matrices if available — side by side
if (!is.null(corr_event) && !is.null(corr_normal)) {
  # Set up side-by-side plotting layout
  par(mfrow = c(1, 2))   # 1 row, 2 columns
  
  corrplot(corr_event, method = "color", type = "upper", order = "hclust",
           tl.col = "black", tl.srt = 45, main = "Correlation (event windows)")
  
  corrplot(corr_normal, method = "color", type = "upper", order = "hclust",
           tl.col = "black", tl.srt = 45, main = "Correlation (normal windows)")
  
  # Reset plotting layout (optional but good practice)
  par(mfrow = c(1, 1))
  
} else if (!is.null(corr_event)) {
  corrplot(corr_event, method = "color", type = "upper", order = "hclust",
           tl.col = "black", tl.srt = 45, main = "Correlation (event windows)")
  
} else if (!is.null(corr_normal)) {
  corrplot(corr_normal, method = "color", type = "upper", order = "hclust",
           tl.col = "black", tl.srt = 45, main = "Correlation (normal windows)")
  
} else {
  cat("Skipping correlation plots — both matrices unavailable.\n")
}

```



```{r}
# Fisher’s r-to-z transformation function
fisher_r_to_z <- function(r) {
  0.5 * log((1 + r) / (1 - r))
}

# Prepare for significance testing
perform_fisher_test <- function(corr_event, corr_normal, n_event, n_normal) {
  # Convert to long format for pairwise comparison
  event_long <- corr_event %>%
    as_tibble(rownames = "station1") %>%
    pivot_longer(-station1, names_to = "station2", values_to = "r_event")

  normal_long <- corr_normal %>%
    as_tibble(rownames = "station1") %>%
    pivot_longer(-station1, names_to = "station2", values_to = "r_normal")

  # Join and clean
  merged <- left_join(event_long, normal_long, by = c("station1", "station2")) %>%
    filter(!is.na(r_event), !is.na(r_normal), station1 != station2)

  if (nrow(merged) == 0) {
    message("No valid correlations found for significance testing.")
    return(NULL)
  }

  # Apply Fisher transformation
  merged <- merged %>%
    mutate(
      z_event = fisher_r_to_z(r_event),
      z_normal = fisher_r_to_z(r_normal),
      z_diff = (z_event - z_normal) /
               sqrt((1 / (n_event - 3)) + (1 / (n_normal - 3))),
      p_value = 2 * (1 - pnorm(abs(z_diff)))
    ) %>%
    mutate(significant = p_value < 0.05)

  return(merged)
}


```

```{r}
fisher_results <- perform_fisher_test(corr_event, corr_normal, n_event, n_normal)
fisher_results %>%
  filter(significant) %>%
  arrange(p_value) %>%
  print()
```
```{r}

plot_fisher_heatmap <- function(fisher_results) {
  if (is.null(fisher_results) || nrow(fisher_results) == 0) {
    cat("No Fisher test results to plot.\n")
    return(NULL)
  }

  ggplot(fisher_results, aes(x = station1, y = station2, fill = z_diff)) +
    geom_tile(color = "grey80") +
    scale_fill_gradient2(
      low = "blue", mid = "white", high = "red",
      midpoint = 0,
      name = "Z difference\n(event - normal)"
    ) +
    coord_fixed() +
    theme_minimal(base_size = 12) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
      panel.grid = element_blank()
    ) +
    ggtitle("Change in correlation between event and normal periods")
}

plot_fisher_heatmap(fisher_results)

```
```{r}
plot_fisher_significant <- function(fisher_results) {
  sig <- fisher_results %>% filter(significant)
  if (nrow(sig) == 0) {
    cat("No significant pairs to plot.\n")
    return(NULL)
  }

  ggplot(sig, aes(x = station1, y = station2, fill = z_diff)) +
    geom_tile(color = "black") +
    scale_fill_gradient2(
      low = "blue", mid = "white", high = "red",
      midpoint = 0,
      name = "Z diff\n(event - normal)"
    ) +
    coord_fixed() +
    theme_minimal(base_size = 12) +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      panel.grid = element_blank()
    ) +
    ggtitle("Station pairs with significant change in correlation (p < 0.05)")
}

plot_fisher_significant(fisher_results)

```


```{r}


# --- 1️⃣ Check sampling interval ---
cat("=== SAMPLING INTERVAL CHECK ===\n")
if (!"time" %in% names(df_anom_coords)) stop("Column 'time' not found in anomaly_df.")
sampling_diff <- diff(sort(unique(df_anom_coords$time)))
cat("Median sampling interval (seconds):", median(as.numeric(sampling_diff, units = "secs")), "\n")
cat("Min sampling interval (seconds):", min(as.numeric(sampling_diff, units = "secs")), "\n")
cat("Max sampling interval (seconds):", max(as.numeric(sampling_diff, units = "secs")), "\n\n")

# --- 2️⃣ Event vs Non-event counts ---
cat("=== EVENT COUNTS ===\n")
cat("Total rows:", nrow(df_anom_coords), "\n")
cat("Event rows:", sum(df_anom_coords$`debris flow`, na.rm = TRUE), "\n")
cat("Non-event rows:", sum(!df_anom_coords$`debris flow`, na.rm = TRUE), "\n\n")

# --- 3️⃣ Event duration summary ---
cat("=== EVENT DURATION (seconds) ===\n")
event_blocks <- df_anom_coords %>%
  arrange(time) %>%
  mutate(group = cumsum(c(0, diff(`debris flow`) != 0))) %>%
  group_by(group) %>%
  summarize(
    start = first(time),
    end = last(time),
    duration_sec = as.numeric(difftime(last(time), first(time), units = "secs")),
    is_event = first(`debris flow`)
  ) %>%
  filter(is_event == TRUE)

if (nrow(event_blocks) == 0) {
  cat("⚠️ No event periods found.\n\n")
} else {
  print(event_blocks)
  cat("Median event duration (minutes):", median(event_blocks$duration_sec) / 60, "\n\n")
}

# --- 4️⃣ Sampling points within a 15-min window ---
cat("=== POINTS PER 15-MIN WINDOW ===\n")
window_size <- 15 * 60 # seconds
counts <- df_anom_coords %>%
  mutate(window_id = floor(as.numeric(difftime(time, min(time), units = "secs")) / window_size)) %>%
  count(window_id)

cat("Median points per window:", median(counts$n), "\n")
cat("Min points per window:", min(counts$n), "\n")
cat("Max points per window:", max(counts$n), "\n")

# Optional: show histogram of number of samples per window
hist(counts$n, breaks = 20, main = "Samples per 15-min window", xlab = "Number of points")

```

```{r}
library(dplyr)
library(lubridate)

event_times <- df_anom_coords %>%
  filter(`debris flow` == TRUE) %>%
  arrange(time)

# Gaps between consecutive event samples
event_gaps <- diff(event_times$time)

cat("Median gap between event samples (seconds):", median(as.numeric(event_gaps, units = "secs")), "\n")
cat("Mean gap between event samples (seconds):", mean(as.numeric(event_gaps, units = "secs")), "\n")
hist(as.numeric(event_gaps, units = "mins"), breaks = 100,
     main = "Time gaps between event points", xlab = "Gap length (minutes)")

```

